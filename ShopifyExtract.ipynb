{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import uuid\n",
    "import platform\n",
    "import logging\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil import tz\n",
    "import dateutil.parser as dp\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendates(shoptimezone, min_date,max_date,rfreq):\n",
    "    to_zone = tz.gettz(shoptimezone)\n",
    "    dateranges = pd.date_range(start=min_date, end=max_date, freq=rfreq, tz=to_zone)\n",
    "    dateranges = dateranges.union([min_date,max_date])\n",
    "    dfdateranges = pd.DataFrame(dateranges)\n",
    "    dfdateranges.columns=['start_date']\n",
    "    dfdateranges['end_date'] = dfdateranges.start_date.shift(-1)\n",
    "    dfdateranges = dfdateranges[:-1]\n",
    "    dfdateranges['end_date'] = dfdateranges['end_date'] + datetime.timedelta(milliseconds=1)\n",
    "    return dfdateranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcurtimeinshoptz(sz):\n",
    "    from_zone = tz.tzlocal()\n",
    "    to_zone = tz.gettz(sz)\n",
    "    utc = datetime.datetime.now()\n",
    "    utc = utc.replace(tzinfo=from_zone)\n",
    "    currentshopdate = utc.astimezone(to_zone)\n",
    "    return currentshopdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getconvtimeinshoptz(sz, t):\n",
    "    to_zone = tz.gettz(sz)\n",
    "    currentshopdate = t.astimezone(to_zone)\n",
    "    return currentshopdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcountandpages(countrurl, headers, cntparams):\n",
    "    totalcnt = requests.get(countrurl, headers = headers, params = cntparams).json()['count']   \n",
    "    nopages = math.ceil(totalcnt/limit) + 1\n",
    "    return totalcnt,nopages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettimezone(shoptimeurl, headers, cntparams):\n",
    "    response = requests.get(shoptimeurl, headers = headers, params = cntparams).json()\n",
    "    df = pd.DataFrame(response['shop'], index=[0])\n",
    "    return df['iana_timezone'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfirstcreationdate(shopifycode, pageurl, headers, params):\n",
    "    params.update({'order' : 'created_at asc'})\n",
    "    response = requests.get(pageurl, headers = headers, params = params).json()\n",
    "    df = pd.DataFrame(response[shopifycode])\n",
    "    min_date = min(df['created_at'])\n",
    "    print(min_date)\n",
    "    return min_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getshopifydates(rtype, rfreq, min_date, max_date, shopifycode, shoptimezone, countrurl, headers, cntparams, pageurl, params):\n",
    "    if (rtype == runtype[0]) or (rtype == runtype[1] and min_date is None and max_date is None):\n",
    "        currentshopdate = getcurtimeinshoptz(shoptimezone)\n",
    "        to_zone = tz.gettz(shoptimezone)\n",
    "        min_date_str = getfirstcreationdate(shopifycode, pageurl, headers, params)\n",
    "        min_date = dp.parse(min_date_str)\n",
    "        min_date = min_date.replace(tzinfo=to_zone)\n",
    "        dates = gendates(shoptimezone, min_date, currentshopdate, rfreq)\n",
    "    elif rtype == runtype[1]:\n",
    "        if max_date is None:    \n",
    "            dates = gendates(shoptimezone, min_date, currentshopdate, rfreq)\n",
    "        else:    \n",
    "            dates = gendates(shoptimezone, min_date, max_date, rfreq)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushtojson(dfcontents, dest_file_name):\n",
    "    dfcontents.to_json(dest_file_name,orient=\"records\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requestshopifydata(shopifycode, pageurl, params): \n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        response = requests_retry_session().get(pageurl, headers = headers, params = params)\n",
    "    except Exception as x:\n",
    "        print('It failed :(', x.__class__.__name__)\n",
    "    else:\n",
    "        print('It eventually worked', response.status_code)\n",
    "    finally:\n",
    "        t1 = time.time()\n",
    "        print('Took', t1 - t0, 'seconds')\n",
    "    #response = requests.get(pageurl, headers = headers, params = params)\n",
    "    df = pd.DataFrame(response.json()[shopifycode])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getclient_details(client_name):\n",
    "    client = bigquery.Client()\n",
    "    query = \"\"\"\n",
    "        select * from sarasdata.client_details\n",
    "        WHERE client_name = @client_name\n",
    "        ORDER BY client_id DESC;\n",
    "        \"\"\"\n",
    "    query_params = [\n",
    "        bigquery.ScalarQueryParameter('client_name', 'STRING', client_name)\n",
    "    ]\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.query_parameters = query_params\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "\n",
    "    query_job.result()  # Wait for job to complete\n",
    "\n",
    "    # Print the results.\n",
    "    destination_table_ref = query_job.destination\n",
    "    table = client.get_table(destination_table_ref)\n",
    "    table_data = None\n",
    "    for row in client.list_rows(table):\n",
    "        table_data = row\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvendor_details(vendor_name):\n",
    "    client = bigquery.Client()\n",
    "    query = \"\"\"\n",
    "        select * from sarasdata.vendor_details\n",
    "        WHERE vendor_name = @vendor_name\n",
    "        ORDER BY vendor_id DESC;\n",
    "        \"\"\"\n",
    "    query_params = [\n",
    "        bigquery.ScalarQueryParameter('vendor_name', 'STRING', vendor_name)\n",
    "    ]\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.query_parameters = query_params\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "\n",
    "    query_job.result()  # Wait for job to complete\n",
    "\n",
    "    # Print the results.\n",
    "    destination_table_ref = query_job.destination\n",
    "    table = client.get_table(destination_table_ref)\n",
    "    table_data = None\n",
    "    for row in client.list_rows(table):\n",
    "        table_data = row\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getclient_shopify_entitilements(client_id):\n",
    "    client = bigquery.Client()\n",
    "    query = \"\"\"\n",
    "        select * from sarasdata.client_shopify_entitilements\n",
    "        WHERE client_id = @client_id\n",
    "        ORDER BY client_id DESC;\n",
    "        \"\"\"\n",
    "    query_params = [\n",
    "        bigquery.ScalarQueryParameter('client_id', 'INTEGER', client_id)\n",
    "    ]\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.query_parameters = query_params\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "\n",
    "    query_job.result()  # Wait for job to complete\n",
    "\n",
    "    # Print the results.\n",
    "    destination_table_ref = query_job.destination\n",
    "    table = client.get_table(destination_table_ref)\n",
    "    table_data = None\n",
    "    for row in client.list_rows(table):\n",
    "        table_data = row\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlastupdateddate(dataset_name, table_name):\n",
    "    client = bigquery.Client()\n",
    "    query = \"select max(updated_at) max_updated_dt from \" + dataset_id + \".\" + table_name + \";\"\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "\n",
    "    query_job.result()  # Wait for job to complete\n",
    "\n",
    "    # Print the results.\n",
    "    destination_table_ref = query_job.destination\n",
    "    table = client.get_table(destination_table_ref)\n",
    "    table_data = None\n",
    "    for row in client.list_rows(table):\n",
    "        table_data = row\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteexistingrows(dataset_name, table_name, ids):\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    query = \"delete from \" + dataset_id + \".\" + table_name + \" where id in UNNEST(@ids);\"\n",
    "    query_params = [\n",
    "        bigquery.ArrayQueryParameter('ids', 'INTEGER', ids)\n",
    "    ]\n",
    "\n",
    "    print(query)\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.use_legacy_sql = False\n",
    "    job_config.query_parameters = query_params\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "\n",
    "    query_job.result()  # Wait for job to complete\n",
    "    \n",
    "    # Print the results.\n",
    "    destination_table_ref = query_job.destination\n",
    "    table = client.get_table(destination_table_ref)\n",
    "    table_data = None\n",
    "    for row in client.list_rows(table):\n",
    "        table_data = row\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createloadtracker(dataset_id,table_name,file_names,date_from,date_to):\n",
    "    load_id = uuid.uuid4()\n",
    "    dfnew = pd.DataFrame(columns=['load_id','dataset_id','table_name','file_names',\n",
    "    'date_from','date_to','loaded_to_bigquery','bigquery_load_date','creation_date',\n",
    "    'update_date','load_script_version','load_script_file_name'])\n",
    "    row = dict()\n",
    "    row['load_id'] = load_id\n",
    "    row['dataset_id'] = dataset_id\n",
    "    row['table_name'] = table_name\n",
    "    row['file_names'] = file_names\n",
    "    row['date_from'] = date_from.replace(tzinfo=None)\n",
    "    row['date_to'] = date_to.replace(tzinfo=None)\n",
    "    row['loaded_to_bigquery'] = 0\n",
    "    row['bigquery_load_date'] = None\n",
    "    row['creation_date'] = datetime.datetime.now()\n",
    "    row['update_date'] = datetime.datetime.now()\n",
    "    row['load_script_version'] = 'v1'\n",
    "    row['load_script_file_name'] = 'shopifyextract.py'\n",
    "    row_s = pd.Series(row)    \n",
    "    print(row_s)\n",
    "    dfnew = dfnew.append(row_s,ignore_index=True)\n",
    "    return dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateloadtracker(filename, dataset_id, file_names, table_name, date_from,date_to, delimitertype, loadtype, skipheader):\n",
    "    delimitertype = 'NEWLINE_DELIMITED_CSV'\n",
    "    loadtype = 'WRITE_APPEND'\n",
    "    loadtracker = createloadtracker(dataset_id,table_name,file_names,date_from,date_to)\n",
    "    loadtracker.to_csv(filename, index=False)\n",
    "    #loadfiletobigquery(filename, dataset_id, 'load_tracker', delimitertype, loadtype, skipheader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadlocalfiletogooglestorage(batfile, source_file_name, dest_file_name):\n",
    "    pass_arg=[]\n",
    "    pass_arg.append(batfile)\n",
    "    pass_arg.append(source_file_name)\n",
    "    pass_arg.append(dest_file_name)\n",
    "    p = Popen(pass_arg, stdout=PIPE, stderr=PIPE)\n",
    "    output, errors = p.communicate()\n",
    "    p.wait() # wait for process to terminate\n",
    "    print(output)\n",
    "    print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadfiletobigquery(file_name, dataset_id, table_name, delimitertype, loadtype, skipheader):\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    table_ref = client.dataset(dataset_id).table(table_name)\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    if skipheader is not None:\n",
    "        job_config.skip_leading_rows = skipheader\n",
    "    job_config.source_format = delimitertype\n",
    "    #if delimitertype == bigquery.SourceFormat.CSV:\n",
    "        #job_config.autodetect = True\n",
    "    job_config.write_disposition = loadtype\n",
    "    \n",
    "    print(dataset_id)\n",
    "    print(file_name)\n",
    "    print(table_ref)\n",
    "    with open(file_name, 'rb') as source_file:\n",
    "        job = client.load_table_from_file(\n",
    "            file_name,\n",
    "            table_ref,\n",
    "            location='US',  # Must match the destination dataset location.\n",
    "            job_config=job_config)  # API request\n",
    "\n",
    "    assert load_job.job_type == 'load'\n",
    "\n",
    "    load_job.result()  # Waits for table load to complete.\n",
    "\n",
    "    assert load_job.state == 'DONE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_path = os.getcwd()\n",
    "gspath = 'gs://sarasmaster'\n",
    "os.chdir(os.getcwd())\n",
    "filesep = '\\\\' if platform.system() == 'Windows' else '/'\n",
    "gssep = '/'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"creds\" + filesep + \"sarasmaster-524142bf5547.json\"\n",
    "gcspath = 'C:\\\\Users\\\\kabhi\\\\AppData\\\\Local\\\\Google\\\\Cloud SDK\\\\google-cloud-sdk\\\\bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + gcspath\n",
    "batfile = app_path + filesep + 'movetogcs.bat' if platform.system() == 'Windows' else app_path + filesep + 'movetogcs.sh'\n",
    "delimitertype = 'NEWLINE_DELIMITED_JSON'\n",
    "loadtype = 'WRITE_APPEND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\logs\\shopify_20180506.log\n"
     ]
    }
   ],
   "source": [
    "client_details = getclient_details('Kopari Beauty')\n",
    "client_shopify_entitilements = getclient_shopify_entitilements(client_details.client_id)\n",
    "shopifyurl= client_shopify_entitilements.shop_url\n",
    "cloud_storage_dir = client_shopify_entitilements.cloud_storage_dir\n",
    "access_token = client_shopify_entitilements.access_token\n",
    "project_id = client_details.project_id\n",
    "dataset_id = client_shopify_entitilements.dataset_id\n",
    "pageno = 1\n",
    "limit = 250\n",
    "\n",
    "filepath = app_path + filesep + client_shopify_entitilements.cloud_storage_dir + filesep + 'shopify'\n",
    "gcspath = gspath + gssep + client_shopify_entitilements.cloud_storage_dir + gssep + 'shopify'\n",
    "logpath = app_path + filesep + client_shopify_entitilements.cloud_storage_dir + filesep + 'logs'\n",
    "loadtrackerfile = app_path + filesep + client_shopify_entitilements.cloud_storage_dir + filesep + 'loadtracker.csv'\n",
    "loadtrackertable = 'load_tracking'\n",
    "hdlr = logging.FileHandler(logpath + filesep + 'shopify_' + datetime.datetime.now().strftime('%Y%m%d') + '.log')\n",
    "logger = logging.getLogger(__name__)\n",
    "print(logpath + filesep + 'shopify_' + datetime.datetime.now().strftime('%Y%m%d') + '.log')\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr) \n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Start Shopify Load Process')\n",
    "\n",
    "status = 'any'\n",
    "runtype = ['full','incremental']\n",
    "headers = {'content-type' : 'application/json', 'X-Shopify-Access-Token' : access_token}\n",
    "urlparams = {'limit': limit, 'status' : status}\n",
    "cnturlparams = {'status' : status}\n",
    "dot = '.'\n",
    "skipheader = None\n",
    "shopurl = shopifyurl + '/admin/shop.json'\n",
    "shopifycodes = {\n",
    "    'shopifycodes': ['orders', 'customers', 'products'],\n",
    "    'pageurl': [shopifyurl + '/admin/orders.json', shopifyurl + '/admin/customers.json', shopifyurl + '/admin/products.json'],\n",
    "    'countrurl': [shopifyurl + '/admin/orders/count.json', shopifyurl + '/admin/customers/count.json', shopifyurl + '/admin/products/count.json'],\n",
    "    'dest_file_name': [filepath + filesep + 'orders' + filesep + 'inbox' + filesep + 'orders', filepath + filesep + 'customers' + filesep + 'inbox' + filesep + 'customers', filepath + filesep + 'inbox' + filesep + 'products' + filesep + 'inbox' + filesep + 'products'],\n",
    "    'gs_file_path': [gcspath + gssep + 'orders' + gssep + 'inbox', gcspath + gssep + 'customers' + gssep + 'inbox', gcspath + gssep + 'products' + gssep + 'inbox'],\n",
    "    'gs_file_name': [gcspath + gssep + 'orders' + gssep + 'orders', gcspath + gssep + 'customers' + gssep + 'customers', gcspath + gssep + 'products' + gssep + 'products'],\n",
    "    'dest_table_name': ['shopify_orders', 'shopify_customers', 'shopify_products'],\n",
    "    'dest_file_type': ['json', 'json', 'json']\n",
    "}\n",
    "\n",
    "dfshopifycodes = pd.DataFrame(shopifycodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Name:orders\n",
      "Total Count:287\n",
      "Total Pages:3\n",
      "Start Date:20180429115246\n",
      "End Date:20180430115246\n",
      "It eventually worked 200\n",
      "Took 0.38675856590270996 seconds\n",
      "It eventually worked 200\n",
      "Took 0.2923312187194824 seconds\n",
      "Number of ids to be checked for delete:287\n",
      "Table Name:orders\n",
      "Total Count:359\n",
      "Total Pages:3\n",
      "Start Date:20180430115246\n",
      "End Date:20180501115246\n",
      "It eventually worked 200\n",
      "Took 0.5299804210662842 seconds\n",
      "It eventually worked 200\n",
      "Took 0.35162925720214844 seconds\n",
      "Number of ids to be checked for delete:359\n",
      "Table Name:orders\n",
      "Total Count:477\n",
      "Total Pages:3\n",
      "Start Date:20180501115246\n",
      "End Date:20180502115246\n",
      "It eventually worked 200\n",
      "Took 0.41157031059265137 seconds\n",
      "It eventually worked 200\n",
      "Took 0.4445641040802002 seconds\n",
      "Number of ids to be checked for delete:477\n",
      "Table Name:orders\n",
      "Total Count:943\n",
      "Total Pages:5\n",
      "Start Date:20180502115246\n",
      "End Date:20180503115246\n",
      "It eventually worked 200\n",
      "Took 0.4367554187774658 seconds\n",
      "It eventually worked 200\n",
      "Took 0.4021928310394287 seconds\n",
      "It eventually worked 200\n",
      "Took 0.3849799633026123 seconds\n",
      "It eventually worked 200\n",
      "Took 0.4113597869873047 seconds\n",
      "Number of ids to be checked for delete:943\n",
      "Table Name:orders\n",
      "Total Count:1283\n",
      "Total Pages:7\n",
      "Start Date:20180503115246\n",
      "End Date:20180504115246\n",
      "It eventually worked 200\n",
      "Took 0.5059618949890137 seconds\n",
      "It eventually worked 200\n",
      "Took 0.42397642135620117 seconds\n",
      "It eventually worked 200\n",
      "Took 0.42969799041748047 seconds\n",
      "It eventually worked 200\n",
      "Took 0.47013092041015625 seconds\n",
      "It eventually worked 200\n",
      "Took 0.42433691024780273 seconds\n",
      "It eventually worked 200\n",
      "Took 0.27755069732666016 seconds\n",
      "Number of ids to be checked for delete:1283\n",
      "Table Name:orders\n",
      "Total Count:1413\n",
      "Total Pages:7\n",
      "Start Date:20180504115246\n",
      "End Date:20180505115246\n",
      "It eventually worked 200\n",
      "Took 0.7845020294189453 seconds\n",
      "It eventually worked 200\n",
      "Took 0.4649791717529297 seconds\n",
      "It eventually worked 200\n",
      "Took 0.4280521869659424 seconds\n",
      "It eventually worked 200\n",
      "Took 0.4448878765106201 seconds\n",
      "It eventually worked 200\n",
      "Took 0.5873072147369385 seconds\n",
      "It eventually worked 200\n",
      "Took 0.36369824409484863 seconds\n",
      "Number of ids to be checked for delete:1413\n",
      "Table Name:orders\n",
      "Total Count:658\n",
      "Total Pages:4\n",
      "Start Date:20180505115246\n",
      "End Date:20180506115246\n",
      "It eventually worked 200\n",
      "Took 0.5629394054412842 seconds\n",
      "It eventually worked 200\n",
      "Took 0.4403092861175537 seconds\n",
      "It eventually worked 200\n",
      "Took 0.34092259407043457 seconds\n",
      "Number of ids to be checked for delete:658\n",
      "Table Name:orders\n",
      "Total Count:120\n",
      "Total Pages:2\n",
      "Start Date:20180506115246\n",
      "End Date:20180506211143\n",
      "It eventually worked 200\n",
      "Took 0.4185791015625 seconds\n",
      "Number of ids to be checked for delete:120\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orders\\inbox\\orders_20180429.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orders\\inbox\\orders_20180430.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orders\\inbox\\orders_20180501.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orders\\inbox\\orders_20180502.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orders\\inbox\\orders_20180503.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orders\\inbox\\orders_20180504.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orders\\inbox\\orders_20180505.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orders\\inbox\\orders_20180506.json\n",
      "bigquery_load_date                                                    None\n",
      "creation_date                                   2018-05-06 23:12:26.751642\n",
      "dataset_id                                                          kopari\n",
      "date_from                                       2018-04-29 11:52:46.001000\n",
      "date_to                                         2018-05-06 21:11:43.118783\n",
      "file_names               C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\orde...\n",
      "load_id                               9fd3d104-6ab3-44e8-95c6-3f6dac653257\n",
      "load_script_file_name                                    shopifyextract.py\n",
      "load_script_version                                                     v1\n",
      "loaded_to_bigquery                                                       0\n",
      "table_name                                                  shopify_orders\n",
      "update_date                                     2018-05-06 23:12:26.751642\n",
      "dtype: object\n",
      "Table Name:customers\n",
      "Total Count:358\n",
      "Total Pages:3\n",
      "Start Date:20180424043129\n",
      "End Date:20180425043129\n",
      "It eventually worked 200\n",
      "Took 5.370610952377319 seconds\n",
      "It eventually worked 200\n",
      "Took 3.1702308654785156 seconds\n",
      "Number of ids to be checked for delete:358\n",
      "Table Name:customers\n",
      "Total Count:445\n",
      "Total Pages:3\n",
      "Start Date:20180425043129\n",
      "End Date:20180426043129\n",
      "It eventually worked 200\n",
      "Took 8.407989025115967 seconds\n",
      "It eventually worked 200\n",
      "Took 6.2006516456604 seconds\n",
      "Number of ids to be checked for delete:445\n",
      "Table Name:customers\n",
      "Total Count:837\n",
      "Total Pages:5\n",
      "Start Date:20180426043129\n",
      "End Date:20180427043129\n",
      "It eventually worked 200\n",
      "Took 7.3767619132995605 seconds\n",
      "It eventually worked 200\n",
      "Took 6.075579643249512 seconds\n",
      "It eventually worked 200\n",
      "Took 7.920271158218384 seconds\n",
      "It eventually worked 200\n",
      "Took 2.423429489135742 seconds\n",
      "Number of ids to be checked for delete:837\n",
      "Table Name:customers\n",
      "Total Count:1351\n",
      "Total Pages:7\n",
      "Start Date:20180427043129\n",
      "End Date:20180428043129\n",
      "It eventually worked 200\n",
      "Took 5.5102012157440186 seconds\n",
      "It eventually worked 200\n",
      "Took 5.296883821487427 seconds\n",
      "It eventually worked 200\n",
      "Took 6.167741060256958 seconds\n",
      "It eventually worked 200\n",
      "Took 7.214537143707275 seconds\n",
      "It eventually worked 200\n",
      "Took 6.385150909423828 seconds\n",
      "It eventually worked 200\n",
      "Took 3.253347158432007 seconds\n",
      "Number of ids to be checked for delete:1351\n",
      "Table Name:customers\n",
      "Total Count:697\n",
      "Total Pages:4\n",
      "Start Date:20180428043129\n",
      "End Date:20180429043129\n",
      "It eventually worked 200\n",
      "Took 5.651193857192993 seconds\n",
      "It eventually worked 200\n",
      "Took 6.011949777603149 seconds\n",
      "It eventually worked 200\n",
      "Took 5.617156744003296 seconds\n",
      "Number of ids to be checked for delete:697\n",
      "Table Name:customers\n",
      "Total Count:638\n",
      "Total Pages:4\n",
      "Start Date:20180429043129\n",
      "End Date:20180430043129\n",
      "It eventually worked 200\n",
      "Took 5.792723655700684 seconds\n",
      "It eventually worked 200\n",
      "Took 7.577444314956665 seconds\n",
      "It eventually worked 200\n",
      "Took 4.195408821105957 seconds\n",
      "Number of ids to be checked for delete:638\n",
      "Table Name:customers\n",
      "Total Count:694\n",
      "Total Pages:4\n",
      "Start Date:20180430043129\n",
      "End Date:20180501043129\n",
      "It eventually worked 200\n",
      "Took 6.737634897232056 seconds\n",
      "It eventually worked 200\n",
      "Took 6.464786529541016 seconds\n",
      "It eventually worked 200\n",
      "Took 6.419403791427612 seconds\n",
      "Number of ids to be checked for delete:694\n",
      "Table Name:customers\n",
      "Total Count:1539\n",
      "Total Pages:8\n",
      "Start Date:20180501043129\n",
      "End Date:20180502043129\n",
      "It eventually worked 200\n",
      "Took 5.916540145874023 seconds\n",
      "It eventually worked 200\n",
      "Took 5.967803716659546 seconds\n",
      "It eventually worked 200\n",
      "Took 5.581532955169678 seconds\n",
      "It eventually worked 200\n",
      "Took 6.098294734954834 seconds\n",
      "It eventually worked 200\n",
      "Took 6.16357684135437 seconds\n",
      "It eventually worked 200\n",
      "Took 8.037205696105957 seconds\n",
      "It eventually worked 200\n",
      "Took 2.0426032543182373 seconds\n",
      "Number of ids to be checked for delete:1539\n",
      "Table Name:customers\n",
      "Total Count:387\n",
      "Total Pages:3\n",
      "Start Date:20180502043129\n",
      "End Date:20180503043129\n",
      "It eventually worked 200\n",
      "Took 5.199848890304565 seconds\n",
      "It eventually worked 200\n",
      "Took 4.54966402053833 seconds\n",
      "Number of ids to be checked for delete:387\n",
      "Table Name:customers\n",
      "Total Count:349\n",
      "Total Pages:3\n",
      "Start Date:20180503043129\n",
      "End Date:20180504043129\n",
      "It eventually worked 200\n",
      "Took 6.007477045059204 seconds\n",
      "It eventually worked 200\n",
      "Took 3.043309211730957 seconds\n",
      "Number of ids to be checked for delete:349\n",
      "Table Name:customers\n",
      "Total Count:365\n",
      "Total Pages:3\n",
      "Start Date:20180504043129\n",
      "End Date:20180505043129\n",
      "It eventually worked 200\n",
      "Took 4.785956621170044 seconds\n",
      "It eventually worked 200\n",
      "Took 3.2808499336242676 seconds\n",
      "Number of ids to be checked for delete:365\n",
      "Table Name:customers\n",
      "Total Count:244\n",
      "Total Pages:2\n",
      "Start Date:20180505043129\n",
      "End Date:20180506043129\n",
      "It eventually worked 200\n",
      "Took 1.8388025760650635 seconds\n",
      "Number of ids to be checked for delete:244\n",
      "Table Name:customers\n",
      "Total Count:252\n",
      "Total Pages:3\n",
      "Start Date:20180506043129\n",
      "End Date:20180506211143\n",
      "It eventually worked 200\n",
      "Took 4.009306907653809 seconds\n",
      "It eventually worked 200\n",
      "Took 0.2950167655944824 seconds\n",
      "Number of ids to be checked for delete:252\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180424.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180425.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180426.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180427.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180428.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180429.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180430.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180501.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180502.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180503.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180504.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180505.json\n",
      "C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\customers\\inbox\\customers_20180506.json\n",
      "bigquery_load_date                                                    None\n",
      "creation_date                                   2018-05-06 23:16:39.894351\n",
      "dataset_id                                                          kopari\n",
      "date_from                                       2018-04-24 04:31:29.001000\n",
      "date_to                                         2018-05-06 21:11:43.118783\n",
      "file_names               C:\\Users\\kabhi\\Desktop\\smd\\kopari\\shopify\\cust...\n",
      "load_id                               8191cb41-0d94-4993-a23f-b0d56d35d028\n",
      "load_script_file_name                                    shopifyextract.py\n",
      "load_script_version                                                     v1\n",
      "loaded_to_bigquery                                                       0\n",
      "table_name                                               shopify_customers\n",
      "update_date                                     2018-05-06 23:16:39.894351\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Name:products\n",
      "Total Count:1\n",
      "Total Pages:2\n",
      "Start Date:20180424091345\n",
      "End Date:20180425091345\n",
      "It eventually worked 200\n",
      "Took 0.19426679611206055 seconds\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\kabhi\\\\Desktop\\\\smd\\\\kopari\\\\shopify\\\\inbox\\\\products\\\\inbox\\\\products_20180424.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-239-9d35828a8e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mlocalfilelist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mgcsfilelist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgcsfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mpushtojson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocalfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of ids to be checked for delete:\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m#deleteexistingrows(dataset_id, row['dest_table_name'], df['id'].tolist())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-179-0ba6cbb9aea1>\u001b[0m in \u001b[0;36mpushtojson\u001b[1;34m(dfcontents, dest_file_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpushtojson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfcontents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdfcontents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_file_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"records\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\datamaster\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression)\u001b[0m\n\u001b[0;32m   1415\u001b[0m                             \u001b[0mforce_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_ascii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_unit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_unit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m                             \u001b[0mdefault_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_handler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1417\u001b[1;33m                             lines=lines, compression=compression)\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\datamaster\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36mto_json\u001b[1;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\datamaster\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\kabhi\\\\Desktop\\\\smd\\\\kopari\\\\shopify\\\\inbox\\\\products\\\\inbox\\\\products_20180424.json'"
     ]
    }
   ],
   "source": [
    "shoptimezone = gettimezone(shopurl, headers, cnturlparams)\n",
    "currentshopdate = getcurtimeinshoptz(shoptimezone)\n",
    "runmode = runtype[1]\n",
    "runfreq = 'D'\n",
    "for row_index,row in dfshopifycodes.iterrows():\n",
    "    lastshopdate = getlastupdateddate(dataset_id, row['dest_table_name']).max_updated_dt\n",
    "    if lastshopdate is not None:\n",
    "        lastshopdate = getconvtimeinshoptz(shoptimezone, lastshopdate)\n",
    "        lastshopdate = lastshopdate + datetime.timedelta(milliseconds=1)\n",
    "        start_date = lastshopdate\n",
    "        end_date = currentshopdate\n",
    "    else:\n",
    "        start_date = None\n",
    "        end_date = None\n",
    "        \n",
    "    dates = getshopifydates(runmode,runfreq,start_date,end_date,row['shopifycodes'], shoptimezone, row['countrurl'], headers, cnturlparams, row['pageurl'], urlparams)\n",
    "    ids = []\n",
    "    localfilelist = []\n",
    "    gcsfilelist = []\n",
    "    for dates_index, dates_row in dates.iterrows():\n",
    "        cntparams = cnturlparams\n",
    "        cntparams.update({'updated_at_min' : dates_row['start_date'],'updated_at_max' : dates_row['end_date']})\n",
    "        totalcnt,nopages = getcountandpages(row['countrurl'], headers, cntparams)\n",
    "        print(\"Table Name:\" + row['shopifycodes'])\n",
    "        print(\"Total Count:\" + str(totalcnt))\n",
    "        print(\"Total Pages:\" + str(nopages))\n",
    "        print(\"Start Date:\" + dates_row['start_date'].strftime('%Y%m%d%H%M%S'))\n",
    "        print(\"End Date:\" + dates_row['end_date'].strftime('%Y%m%d%H%M%S'))\n",
    "        df = pd.DataFrame()\n",
    "        for i in range(1,nopages):\n",
    "            params = urlparams\n",
    "            params.update({'page': i,'updated_at_min' : dates_row['start_date'],'updated_at_max' : dates_row['end_date']})\n",
    "            df1 = requestshopifydata(row['shopifycodes'], row['pageurl'], params)\n",
    "            df=df.append(df1,ignore_index=True)\n",
    "            time.sleep(1)\n",
    "        ids.extend(df['id'].tolist()) if df.shape[0] > 0 else ids\n",
    "        localfilename = row['dest_file_name'] + '_' + dates_row['start_date'].strftime('%Y%m%d') + dot + row['dest_file_type']\n",
    "        gcsfilename = row['gs_file_name'] + '_' + dates_row['start_date'].strftime('%Y%m%d') + dot + row['dest_file_type']\n",
    "        localfilelist.append(localfilename)\n",
    "        gcsfilelist.append(gcsfilename)\n",
    "        pushtojson(df, localfilename)\n",
    "        print(\"Number of ids to be checked for delete:\" + str(len(df['id'].tolist())))\n",
    "        #deleteexistingrows(dataset_id, row['dest_table_name'], df['id'].tolist())        \n",
    "\n",
    "    \n",
    "    for localfilename in localfilelist:\n",
    "        print(localfilename)\n",
    "        #loadlocalfiletogooglestorage(batfile, localfilename, row['gs_file_path'])\n",
    "    filenames = ','.join(localfilelist)\n",
    "    updateloadtracker(loadtrackerfile, dataset_id, filenames, row['dest_table_name'], start_date, end_date, delimitertype, loadtype, skipheader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
